{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import ast\n",
    "import os\n",
    "import json\n",
    "import sys\n",
    "import ast\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#for reading desired phrase structure\n",
    "def parse_tokens_from_phrase_structure(phrase_stucture_file):\n",
    "    tokens = []\n",
    "    with open(phrase_stucture_file, 'r') as f:\n",
    "        for l in f:\n",
    "            fields = l.split('\\t')\n",
    "            ph_tokens = ast.literal_eval(fields[3])\n",
    "            tokens.extend(ph_tokens)\n",
    "    return tokens\n",
    "\n",
    "#run espeak with mbrola dict to get phonetic trancription of word\n",
    "def get_phonetic_transcription(word):\n",
    "    command = 'espeak -v mb-es1 -q --pho \"' + word + '\"'\n",
    "    cmd_tokens = command.split()\n",
    "    output = subprocess.check_output(cmd_tokens)\n",
    "    output_str = output.decode()\n",
    "    phon_seq = [l.split('\\t')[0] for l in output_str.split('\\n') if l and not l.startswith('_')]\n",
    "    phon_seq_str = ''.join(phon_seq)\n",
    "    return phon_seq, phon_seq_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "phonetic_dict_old = phonetic_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s2_7_0156.subtitle_raw.structure.txt\n",
      "s2_5_0346.subtitle.structure.txt\n",
      "s3_2_0031.subtitle_raw.structure.txt\n",
      "s2_7_0143.subtitle_raw.structure.txt\n",
      "s3_8_0370.subtitle_raw.structure.txt\n",
      "s3_6_0096.subtitle_raw.structure.txt\n",
      "s3_8_0289.subtitle_raw.structure.txt\n",
      "s2_8_0062.subtitle_raw.structure.txt\n",
      "s2_5_0387.subtitle.structure.txt\n",
      "s2_4_0314.subtitle.structure.txt\n"
     ]
    }
   ],
   "source": [
    "#PREPARE PHONETIC LEXICON\n",
    "#builds a phonetic lexicon out of the words in the structure files in given directory\n",
    "#phonetic_dict = {}\n",
    "\n",
    "mt_output_dir = '/home/alp/Documents/playground-linux/SugarDub/sub_synthesis_redo/structure'\n",
    "\n",
    "for root, direc, files in os.walk(mt_output_dir):\n",
    "    for file in files:\n",
    "        if file.endswith('structure.txt'):\n",
    "            print(file)\n",
    "            words = parse_tokens_from_phrase_structure(os.path.join(root,file))\n",
    "            for word in words:\n",
    "                if not word in phonetic_dict.keys():\n",
    "                    phonetic_dict[word], _ = get_phonetic_transcription(word)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#write dict to json file\n",
    "with open('heroes_eval_phonetic_dict_proper_wsubs.txt', 'w') as file:\n",
    "     file.write(json.dumps(phonetic_dict, indent=4)) # use `json.loads` to do the reverse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#read dict from file\n",
    "with open('heroes_eval_phonetic_dict.txt', 'r') as file:\n",
    "     phonetic_dict = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def generate_pho(transcription_file, output_file):\n",
    "    with open(transcription_file, 'r') as f:\n",
    "        transcription = f.read()\n",
    "        \n",
    "    command = 'espeak -v mb-es1 -q --pho --phonout=' + output_file + ' -f ' + transcription_file\n",
    "    cmd_tokens = command.split()\n",
    "    output = subprocess.check_output(cmd_tokens)\n",
    "    output_str = output.decode()\n",
    "    return output_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3_8_0370.subtitle_raw.transcript.txt\n",
      "s2_8_0062.subtitle_raw.transcript.txt\n",
      "s3_2_0031.subtitle_raw.transcript.txt\n",
      "s2_7_0156.subtitle_raw.transcript.txt\n",
      "s3_6_0096.subtitle_raw.transcript.txt\n",
      "s3_8_0289.subtitle_raw.transcript.txt\n",
      "s2_4_0314.subtitle.transcript.txt\n",
      "s2_5_0346.subtitle.transcript.txt\n",
      "s2_5_0387.subtitle.transcript.txt\n",
      "s2_7_0143.subtitle_raw.transcript.txt\n"
     ]
    }
   ],
   "source": [
    "#CREATE DEFAULT PHO FILES\n",
    "mt_output_dir = '/home/alp/Documents/playground-linux/SugarDub/sub_synthesis_redo/structure/'\n",
    "default_pho_dir = '/home/alp/Documents/playground-linux/SugarDub/sub_synthesis_redo/default_pho/'\n",
    "\n",
    "for root, direc, files in os.walk(mt_output_dir):\n",
    "    for file in files:\n",
    "        if file.endswith('transcript.txt'):\n",
    "            print(file)\n",
    "            file_id = file.split('.')[0]\n",
    "            \n",
    "            pho_out = os.path.join(default_pho_dir, file_id + '.default.pho')\n",
    "            \n",
    "            generate_pho(os.path.join(root,file), pho_out)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#FUNCTIONS FOR SYNTHESIS BENDING\n",
    "#main\n",
    "def bend_pho_to_structure(phrase_structure_file, default_pho_file, output_pho_file, verbose=False):\n",
    "    phrase_structure = parse_phrase_structure(phrase_structure_file)\n",
    "    default_phoneme_data = parse_pho(default_pho_file)\n",
    "\n",
    "    phoneme_seq = get_phoneme_seq(default_phoneme_data)\n",
    "\n",
    "    if verbose: print(phoneme_seq)\n",
    "\n",
    "    desired_phrase_info = []\n",
    "    phrase_boundaries = []\n",
    "    phrase_durations = []\n",
    "    phrase_pausings = []\n",
    "    search_index = 0\n",
    "    for phrase_tokens, start_time, end_time, pause_after in phrase_structure:\n",
    "\n",
    "        search_beginning_index = search_index\n",
    "        desired_phrase_duration = (end_time - start_time)* 1000\t#desired duration\n",
    "        desired_pause = int(pause_after * 1000)\n",
    "\n",
    "        if verbose: \n",
    "            print(\"====================\")\n",
    "            print('search_beginning_index', search_beginning_index)\n",
    "        for token_index, token in enumerate(phrase_tokens):\n",
    "            phoneme_rep = morpheme2phoneme(token, phonetic_dict)\n",
    "\n",
    "            word_begin = phoneme_seq.find(phoneme_rep, search_beginning_index)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#FUNCTIONS FOR SYNTHESIS BENDING\n",
    "#main\n",
    "def bend_pho_to_structure(phrase_structure_file, default_pho_file, output_pho_file=None, bend=True, verbose=False):\n",
    "    phrase_structure = parse_phrase_structure(phrase_structure_file)\n",
    "    default_phoneme_data = parse_pho(default_pho_file, skip_silence=True)\n",
    "\n",
    "    phoneme_seq = get_phoneme_seq(default_phoneme_data)\n",
    "\n",
    "    if verbose: print(phoneme_seq)\n",
    "\n",
    "    desired_phrase_info = []\n",
    "    phrase_boundaries = []\n",
    "    phrase_durations = []\n",
    "    phrase_pausings = []\n",
    "    phrase_begin_index = 0\n",
    "    at_default_phrase_duration = 0\n",
    "    for phrase_id, (phrase_tokens, start_time, end_time, pause_after) in enumerate(phrase_structure):\n",
    "\n",
    "        search_beginning_index = phrase_begin_index\n",
    "        \n",
    "        if verbose: \n",
    "            print(\"====================\")\n",
    "            print('search_beginning_index', search_beginning_index)\n",
    "        for token_index, token in enumerate(phrase_tokens):\n",
    "            phoneme_rep = morpheme2phoneme(token, phonetic_dict)\n",
    "\n",
    "            #word_begin = KnuthMorrisPratt(phoneme_seq, phoneme_rep, search_beginning_index)\n",
    "            word_begin = search_beginning_index\n",
    "\n",
    "            word_end = word_begin + len(phoneme_rep)\n",
    "            word_length = word_end - word_begin\n",
    "            if verbose: print(\"%s %i - %i\\t %s\"%(token, word_begin, word_end, ''.join(phoneme_seq[word_begin: word_end])))\n",
    "            search_beginning_index = word_end\n",
    "            if word_begin == -1:\n",
    "                return False\n",
    "\n",
    "        default_phrase_duration = get_duration_of_interval(default_phoneme_data, phrase_begin_index, word_end)\n",
    "        at_default_phrase_duration += default_phrase_duration\n",
    "        if verbose: print('--> default phrase duration', default_phrase_duration)\n",
    "        if verbose: print('--> at_default_phrase_duration', at_default_phrase_duration)\n",
    "\n",
    "        if bend:\n",
    "            desired_phrase_duration = (end_time - start_time)* 1000\t#desired duration\n",
    "            desired_pause = int(pause_after * 1000)\n",
    "            if verbose: print('--> desired phrase duration', desired_phrase_duration)\n",
    "            bend_ratio = desired_phrase_duration / default_phrase_duration\n",
    "        else:\n",
    "            bend_ratio = 1.0\n",
    "            if phrase_id + 1 < len(phrase_structure):\n",
    "                sub_interval = phrase_structure[phrase_id + 1][1] - at_default_phrase_duration/1000\n",
    "                desired_pause = int(sub_interval * 1000)\n",
    "            else:\n",
    "                desired_pause = 0\n",
    "\n",
    "        desired_phrase_info.append(((phrase_begin_index, word_end), bend_ratio, desired_pause))\n",
    "        at_default_phrase_duration += desired_pause\n",
    "        \n",
    "        if verbose: \n",
    "            print(\"====================\")\n",
    "            print(\"interval\", (phrase_begin_index, word_end))\n",
    "            print(\"ratio\", bend_ratio)\n",
    "            print(\"pause\", desired_pause)\n",
    "            print(\"====================\\n\")\n",
    "            \n",
    "            \n",
    "        phrase_begin_index = search_beginning_index\n",
    "    if verbose: \n",
    "        print(\"--------------------========desired phrasing========--------------------\")\n",
    "        print(desired_phrase_info)\n",
    "        \n",
    "\n",
    "    #bend the durations of the phrases and form the desired phoneme data\n",
    "    bent_phoneme_data = []\n",
    "    for (search_beginning_index, end_index), bend_ratio, pause_after in desired_phrase_info:\n",
    "        if verbose: print('desired_phrase_info: %i-%i, %f, %f'%(search_beginning_index, end_index, bend_ratio, pause_after))\n",
    "        for phoneme_info in default_phoneme_data[search_beginning_index:end_index]:\n",
    "            if verbose: \n",
    "                print('default_phoneme_info', phoneme_info)\n",
    "            new_duration = int(float(phoneme_info[1]) * bend_ratio)\n",
    "            new_phoneme_info = (phoneme_info[0], '%i'%new_duration, phoneme_info[2])\n",
    "            if verbose: \n",
    "                print('new_phoneme_info', new_phoneme_info)\n",
    "                print('...')\n",
    "            bent_phoneme_data.append(new_phoneme_info)\n",
    "\n",
    "        pause_info = ('_', pause_after, [])\n",
    "        bent_phoneme_data.append(pause_info)\n",
    "        if verbose: \n",
    "            print('pause_info', pause_info)\n",
    "        \n",
    "    #kill last pause\n",
    "    bent_phoneme_data.pop()\n",
    "    bent_phoneme_data.append(('_', 100, []))\n",
    "    bent_phoneme_data.append(('_', 1, []))\n",
    "\n",
    "    #write bent_phoneme_data to pho file\n",
    "    if output_pho_file:\n",
    "        with open(output_pho_file, 'w') as f:\n",
    "            for i, phoneme_info in enumerate(bent_phoneme_data):\n",
    "                f.write(\"%s\\t%s\\t%s\"%(phoneme_info[0], phoneme_info[1], ' '.join(phoneme_info[2])))\n",
    "                if not i == len(bent_phoneme_data):\n",
    "                    f.write(\"\\n\")\n",
    "    \n",
    "    return True, bent_phoneme_data\n",
    "   \n",
    "    \n",
    "#for reading desired phrase structure\n",
    "def parse_phrase_structure(phrase_stucture_file):\n",
    "    phrase_structure = []\n",
    "    with open(phrase_stucture_file, 'r') as f:\n",
    "        for l in f:\n",
    "            fields = l.split('\\t')\n",
    "            start_time = float(fields[0])\n",
    "            end_time = float(fields[1])\n",
    "            pause_after = float(fields[2])\n",
    "            tokens = ast.literal_eval(fields[3])\n",
    "            phrase_structure.append((tokens, start_time, end_time, pause_after))\n",
    "    return phrase_structure\n",
    "\n",
    "\n",
    "#pho file parser for reading default phoneme timings\n",
    "def parse_pho(pho_file, skip_silence=False):\n",
    "    phoneme_data = []\n",
    "    with open(pho_file, 'r') as f:\n",
    "        for l in f:\n",
    "            l_elems = l.split()\n",
    "            if l_elems:\n",
    "                if skip_silence and l_elems[0] == '_':\n",
    "                    continue\n",
    "                if len(l_elems) == 2:\n",
    "                    phoneme_data.append((l_elems[0], l_elems[1], []))\n",
    "                else:\n",
    "                    phoneme_data.append((l_elems[0], l_elems[1], l_elems[2:]))\n",
    "\n",
    "    return phoneme_data\n",
    "\n",
    "def get_phoneme_seq(phoneme_data):\n",
    "    phoneme_list = []\n",
    "    for phon_info in phoneme_data:\n",
    "        phoneme_list.append(phon_info[0])\n",
    "    return phoneme_list\n",
    "    #return ''.join(phoneme_list)\n",
    "\n",
    "def morpheme2phoneme(morpheme, phonetic_dict):\n",
    "    try:\n",
    "        return phonetic_dict[morpheme]\n",
    "    except:\n",
    "        print(\"%s not in dict\"%morpheme) #TODO\n",
    "        return 0\n",
    "\n",
    "def get_duration_of_interval(phoneme_data, start_index, end_index):\n",
    "    duration = 0\n",
    "    for phoneme_info in phoneme_data[start_index: end_index]:\n",
    "        duration += int(phoneme_info[1])\n",
    "    return duration\n",
    "\n",
    "def KnuthMorrisPratt(text, pattern, search_from):\n",
    "\n",
    "    '''Yields all starting positions of copies of the pattern in the text.\n",
    "Calling conventions are similar to string.find, but its arguments can be\n",
    "lists or iterators, not just strings, it returns all matches, not just\n",
    "the first one, and it does not need the whole text in memory at once.\n",
    "Whenever it yields, it will have read the text exactly up to and including\n",
    "the match that caused the yield.'''\n",
    "\n",
    "    # allow indexing into pattern and protect against change during yield\n",
    "    pattern = list(pattern)\n",
    "\n",
    "    # build table of shift amounts\n",
    "    shifts = [1] * (len(pattern) + 1)\n",
    "    shift = 1\n",
    "    for pos in range(len(pattern)):\n",
    "        while shift <= pos and pattern[pos] != pattern[pos-shift]:\n",
    "            shift += shifts[pos-shift]\n",
    "        shifts[pos+1] = shift\n",
    "\n",
    "    # do the actual search\n",
    "    startPos = 0\n",
    "    matchLen = 0\n",
    "    for c in text[search_from:]:\n",
    "        while matchLen == len(pattern) or \\\n",
    "              matchLen >= 0 and pattern[matchLen] != c:\n",
    "            startPos += shifts[matchLen]\n",
    "            matchLen -= shifts[matchLen]\n",
    "        matchLen += 1\n",
    "        if matchLen == len(pattern):\n",
    "            return startPos + search_from\n",
    "    \n",
    "    return -1 #not found\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a', 'd', 'a', 'm', 'e', 'r', 'a', 'e', 'l', 'b', 'i', 's', 'i', 'o', 'n', 'a', 'r', 'i', 'o', 'p', 'e', 'r', 'o', 'k', 'o', 'n', 'e', 's', 't', 'o', 's', 'p', 'o', 'd', 'e', 'r', 'e', 's', 'a', 'b', 'e', 'T', 'e', 's', 'l', 'a', 'x', 'e', 'n', 't', 'e', 's', 'e', 'b', 'e', 'a', 's', 'i', 'm', 'i', 's', 'm', 'a', 'k', 'o', 'm', 'o', 'u', 'n', 'd', 'i', 'o', 's']\n",
      "====================\n",
      "search_beginning_index 0\n",
      "adam 0 - 4\t adam\n",
      "era 4 - 7\t era\n",
      "el 7 - 9\t el\n",
      "visionario. 9 - 19\t bisionario\n",
      "--> default phrase duration 1103\n",
      "--> at_default_phrase_duration 1103\n",
      "====================\n",
      "interval (0, 19)\n",
      "ratio 1.0\n",
      "pause 1567\n",
      "====================\n",
      "\n",
      "====================\n",
      "search_beginning_index 19\n",
      "pero 19 - 23\t pero\n",
      "con 23 - 26\t kon\n",
      "estos 26 - 31\t estos\n",
      "poderes 31 - 38\t poderes\n",
      "a 38 - 39\t a\n",
      "veces 39 - 44\t beTes\n",
      "la 44 - 46\t la\n",
      "gente 46 - 51\t xente\n",
      "se 51 - 53\t se\n",
      "vea 53 - 56\t bea\n",
      "si 56 - 58\t si\n",
      "misma 58 - 63\t misma\n",
      "como 63 - 67\t komo\n",
      "un 67 - 69\t un\n",
      "dios 69 - 73\t dios\n",
      "--> default phrase duration 3562\n",
      "--> at_default_phrase_duration 6232\n",
      "====================\n",
      "interval (19, 73)\n",
      "ratio 1.0\n",
      "pause 0\n",
      "====================\n",
      "\n",
      "--------------------========desired phrasing========--------------------\n",
      "[((0, 19), 1.0, 1567), ((19, 73), 1.0, 0)]\n",
      "desired_phrase_info: 0-19, 1.000000, 1567.000000\n",
      "default_phoneme_info ('a', '49', ['0', '117', '80', '109', '100', '109'])\n",
      "new_phoneme_info ('a', '49', ['0', '117', '80', '109', '100', '109'])\n",
      "...\n",
      "default_phoneme_info ('d', '65', [])\n",
      "new_phoneme_info ('d', '65', [])\n",
      "...\n",
      "default_phoneme_info ('a', '38', ['0', '110', '80', '106', '100', '106'])\n",
      "new_phoneme_info ('a', '38', ['0', '110', '80', '106', '100', '106'])\n",
      "...\n",
      "default_phoneme_info ('m', '65', [])\n",
      "new_phoneme_info ('m', '65', [])\n",
      "...\n",
      "default_phoneme_info ('e', '47', ['0', '103', '80', '96', '100', '96'])\n",
      "new_phoneme_info ('e', '47', ['0', '103', '80', '96', '100', '96'])\n",
      "...\n",
      "default_phoneme_info ('r', '65', [])\n",
      "new_phoneme_info ('r', '65', [])\n",
      "...\n",
      "default_phoneme_info ('a', '38', ['0', '96', '80', '92', '100', '92'])\n",
      "new_phoneme_info ('a', '38', ['0', '96', '80', '92', '100', '92'])\n",
      "...\n",
      "default_phoneme_info ('e', '36', ['0', '97', '80', '93', '100', '93'])\n",
      "new_phoneme_info ('e', '36', ['0', '97', '80', '93', '100', '93'])\n",
      "...\n",
      "default_phoneme_info ('l', '65', [])\n",
      "new_phoneme_info ('l', '65', [])\n",
      "...\n",
      "default_phoneme_info ('b', '65', [])\n",
      "new_phoneme_info ('b', '65', [])\n",
      "...\n",
      "default_phoneme_info ('i', '32', ['0', '103', '80', '96', '100', '96'])\n",
      "new_phoneme_info ('i', '32', ['0', '103', '80', '96', '100', '96'])\n",
      "...\n",
      "default_phoneme_info ('s', '100', [])\n",
      "new_phoneme_info ('s', '100', [])\n",
      "...\n",
      "default_phoneme_info ('i', '65', [])\n",
      "new_phoneme_info ('i', '65', [])\n",
      "...\n",
      "default_phoneme_info ('o', '32', ['0', '96', '80', '92', '100', '92'])\n",
      "new_phoneme_info ('o', '32', ['0', '96', '80', '92', '100', '92'])\n",
      "...\n",
      "default_phoneme_info ('n', '65', [])\n",
      "new_phoneme_info ('n', '65', [])\n",
      "...\n",
      "default_phoneme_info ('a', '69', ['0', '105', '80', '81', '100', '81'])\n",
      "new_phoneme_info ('a', '69', ['0', '105', '80', '81', '100', '81'])\n",
      "...\n",
      "default_phoneme_info ('r', '65', [])\n",
      "new_phoneme_info ('r', '65', [])\n",
      "...\n",
      "default_phoneme_info ('i', '65', [])\n",
      "new_phoneme_info ('i', '65', [])\n",
      "...\n",
      "default_phoneme_info ('o', '77', ['0', '84', '80', '78', '100', '78'])\n",
      "new_phoneme_info ('o', '77', ['0', '84', '80', '78', '100', '78'])\n",
      "...\n",
      "pause_info ('_', 1567, [])\n",
      "desired_phrase_info: 19-73, 1.000000, 0.000000\n",
      "default_phoneme_info ('p', '80', [])\n",
      "new_phoneme_info ('p', '80', [])\n",
      "...\n",
      "default_phoneme_info ('e', '45', ['0', '94', '20', '94', '40', '94', '59', '95', '80', '95', '100', '95'])\n",
      "new_phoneme_info ('e', '45', ['0', '94', '20', '94', '40', '94', '59', '95', '80', '95', '100', '95'])\n",
      "...\n",
      "default_phoneme_info ('r', '65', [])\n",
      "new_phoneme_info ('r', '65', [])\n",
      "...\n",
      "default_phoneme_info ('o', '38', ['0', '95', '20', '95', '40', '96', '59', '96', '80', '96', '100', '96'])\n",
      "new_phoneme_info ('o', '38', ['0', '95', '20', '95', '40', '96', '59', '96', '80', '96', '100', '96'])\n",
      "...\n",
      "default_phoneme_info ('k', '102', [])\n",
      "new_phoneme_info ('k', '102', [])\n",
      "...\n",
      "default_phoneme_info ('o', '36', ['0', '97', '20', '97', '40', '98', '59', '98', '80', '98', '100', '98'])\n",
      "new_phoneme_info ('o', '36', ['0', '97', '20', '97', '40', '98', '59', '98', '80', '98', '100', '98'])\n",
      "...\n",
      "default_phoneme_info ('n', '65', [])\n",
      "new_phoneme_info ('n', '65', [])\n",
      "...\n",
      "default_phoneme_info ('e', '45', ['0', '117', '80', '109', '100', '109'])\n",
      "new_phoneme_info ('e', '45', ['0', '117', '80', '109', '100', '109'])\n",
      "...\n",
      "default_phoneme_info ('s', '89', [])\n",
      "new_phoneme_info ('s', '89', [])\n",
      "...\n",
      "default_phoneme_info ('t', '50', [])\n",
      "new_phoneme_info ('t', '50', [])\n",
      "...\n",
      "default_phoneme_info ('o', '41', ['0', '110', '80', '106', '100', '106'])\n",
      "new_phoneme_info ('o', '41', ['0', '110', '80', '106', '100', '106'])\n",
      "...\n",
      "default_phoneme_info ('s', '114', [])\n",
      "new_phoneme_info ('s', '114', [])\n",
      "...\n",
      "default_phoneme_info ('p', '61', [])\n",
      "new_phoneme_info ('p', '61', [])\n",
      "...\n",
      "default_phoneme_info ('o', '36', ['0', '111', '80', '107', '100', '107'])\n",
      "new_phoneme_info ('o', '36', ['0', '111', '80', '107', '100', '107'])\n",
      "...\n",
      "default_phoneme_info ('d', '65', [])\n",
      "new_phoneme_info ('d', '65', [])\n",
      "...\n",
      "default_phoneme_info ('e', '69', ['0', '108', '26', '90', '54', '83', '66', '83', '80', '86', '100', '86'])\n",
      "new_phoneme_info ('e', '69', ['0', '108', '26', '90', '54', '83', '66', '83', '80', '86', '100', '86'])\n",
      "...\n",
      "default_phoneme_info ('r', '65', [])\n",
      "new_phoneme_info ('r', '65', [])\n",
      "...\n",
      "default_phoneme_info ('e', '46', ['0', '88', '20', '90', '40', '92', '59', '94', '80', '96', '100', '96'])\n",
      "new_phoneme_info ('e', '46', ['0', '88', '20', '90', '40', '92', '59', '94', '80', '96', '100', '96'])\n",
      "...\n",
      "default_phoneme_info ('s', '140', [])\n",
      "new_phoneme_info ('s', '140', [])\n",
      "...\n",
      "default_phoneme_info ('a', '40', ['0', '94', '20', '95', '40', '96', '59', '97', '80', '99', '100', '99'])\n",
      "new_phoneme_info ('a', '40', ['0', '94', '20', '95', '40', '96', '59', '97', '80', '99', '100', '99'])\n",
      "...\n",
      "default_phoneme_info ('b', '65', [])\n",
      "new_phoneme_info ('b', '65', [])\n",
      "...\n",
      "default_phoneme_info ('e', '47', ['0', '117', '80', '109', '100', '109'])\n",
      "new_phoneme_info ('e', '47', ['0', '117', '80', '109', '100', '109'])\n",
      "...\n",
      "default_phoneme_info ('T', '113', [])\n",
      "new_phoneme_info ('T', '113', [])\n",
      "...\n",
      "default_phoneme_info ('e', '41', ['0', '110', '80', '106', '100', '106'])\n",
      "new_phoneme_info ('e', '41', ['0', '110', '80', '106', '100', '106'])\n",
      "...\n",
      "default_phoneme_info ('s', '100', [])\n",
      "new_phoneme_info ('s', '100', [])\n",
      "...\n",
      "default_phoneme_info ('l', '65', [])\n",
      "new_phoneme_info ('l', '65', [])\n",
      "...\n",
      "default_phoneme_info ('a', '38', ['0', '111', '80', '107', '100', '107'])\n",
      "new_phoneme_info ('a', '38', ['0', '111', '80', '107', '100', '107'])\n",
      "...\n",
      "default_phoneme_info ('x', '119', [])\n",
      "new_phoneme_info ('x', '119', [])\n",
      "...\n",
      "default_phoneme_info ('e', '33', ['0', '112', '80', '105', '100', '105'])\n",
      "new_phoneme_info ('e', '33', ['0', '112', '80', '105', '100', '105'])\n",
      "...\n",
      "default_phoneme_info ('n', '62', ['100', '97'])\n",
      "new_phoneme_info ('n', '62', ['100', '97'])\n",
      "...\n",
      "default_phoneme_info ('t', '69', [])\n",
      "new_phoneme_info ('t', '69', [])\n",
      "...\n",
      "default_phoneme_info ('e', '41', ['0', '105', '80', '101', '100', '101'])\n",
      "new_phoneme_info ('e', '41', ['0', '105', '80', '101', '100', '101'])\n",
      "...\n",
      "default_phoneme_info ('s', '100', [])\n",
      "new_phoneme_info ('s', '100', [])\n",
      "...\n",
      "default_phoneme_info ('e', '40', ['0', '107', '80', '102', '100', '102'])\n",
      "new_phoneme_info ('e', '40', ['0', '107', '80', '102', '100', '102'])\n",
      "...\n",
      "default_phoneme_info ('b', '65', [])\n",
      "new_phoneme_info ('b', '65', [])\n",
      "...\n",
      "default_phoneme_info ('e', '47', ['0', '108', '80', '100', '100', '100'])\n",
      "new_phoneme_info ('e', '47', ['0', '108', '80', '100', '100', '100'])\n",
      "...\n",
      "default_phoneme_info ('a', '41', ['0', '101', '80', '96', '100', '96'])\n",
      "new_phoneme_info ('a', '41', ['0', '101', '80', '96', '100', '96'])\n",
      "...\n",
      "default_phoneme_info ('s', '100', [])\n",
      "new_phoneme_info ('s', '100', [])\n",
      "...\n",
      "default_phoneme_info ('i', '34', ['0', '102', '80', '98', '100', '98'])\n",
      "new_phoneme_info ('i', '34', ['0', '102', '80', '98', '100', '98'])\n",
      "...\n",
      "default_phoneme_info ('m', '65', [])\n",
      "new_phoneme_info ('m', '65', [])\n",
      "...\n",
      "default_phoneme_info ('i', '44', ['0', '103', '80', '96', '100', '96'])\n",
      "new_phoneme_info ('i', '44', ['0', '103', '80', '96', '100', '96'])\n",
      "...\n",
      "default_phoneme_info ('s', '100', [])\n",
      "new_phoneme_info ('s', '100', [])\n",
      "...\n",
      "default_phoneme_info ('m', '65', [])\n",
      "new_phoneme_info ('m', '65', [])\n",
      "...\n",
      "default_phoneme_info ('a', '38', ['0', '96', '80', '92', '100', '92'])\n",
      "new_phoneme_info ('a', '38', ['0', '96', '80', '92', '100', '92'])\n",
      "...\n",
      "default_phoneme_info ('k', '102', [])\n",
      "new_phoneme_info ('k', '102', [])\n",
      "...\n",
      "default_phoneme_info ('o', '43', ['0', '103', '80', '96', '100', '96'])\n",
      "new_phoneme_info ('o', '43', ['0', '103', '80', '96', '100', '96'])\n",
      "...\n",
      "default_phoneme_info ('m', '65', [])\n",
      "new_phoneme_info ('m', '65', [])\n",
      "...\n",
      "default_phoneme_info ('o', '38', ['0', '96', '80', '92', '100', '92'])\n",
      "new_phoneme_info ('o', '38', ['0', '96', '80', '92', '100', '92'])\n",
      "...\n",
      "default_phoneme_info ('u', '48', ['0', '103', '80', '96', '100', '96'])\n",
      "new_phoneme_info ('u', '48', ['0', '103', '80', '96', '100', '96'])\n",
      "...\n",
      "default_phoneme_info ('n', '87', ['100', '88'])\n",
      "new_phoneme_info ('n', '87', ['100', '88'])\n",
      "...\n",
      "default_phoneme_info ('d', '65', [])\n",
      "new_phoneme_info ('d', '65', [])\n",
      "...\n",
      "default_phoneme_info ('i', '65', [])\n",
      "new_phoneme_info ('i', '65', [])\n",
      "...\n",
      "default_phoneme_info ('o', '85', ['0', '102', '80', '76', '100', '76'])\n",
      "new_phoneme_info ('o', '85', ['0', '102', '80', '76', '100', '76'])\n",
      "...\n",
      "default_phoneme_info ('s', '140', [])\n",
      "new_phoneme_info ('s', '140', [])\n",
      "...\n",
      "pause_info ('_', 0, [])\n"
     ]
    }
   ],
   "source": [
    "#bend sample for subtitle synthesis\n",
    "sample_id = 's2_7_00'\n",
    "phrase_structure_file = 'sub_synthesis/structure/' + sample_id + '.subtitle.structure.txt'\n",
    "default_pho_file = 'sub_synthesis/default_pho/' + sample_id + '.default.pho'\n",
    "output_pho_file = sample_id + '.subunbent.pho'\n",
    "def_p = bend_pho_to_structure(phrase_structure_file, default_pho_file, output_pho_file, bend=False, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['k', 'e', 'a', 'T', 'e', 's', 'a', 'k', 'i', 'd', 'o', 'n', 'd', 'e', 'e', 's', 't', 'a', 'm', 'o', 's']\n",
      "====================\n",
      "search_beginning_index 0\n",
      "qué 0 - 2\t ke\n",
      "--> default phrase duration 160\n",
      "--> at_default_phrase_duration 160\n",
      "--> desired phrase duration 320.0\n",
      "====================\n",
      "interval (0, 2)\n",
      "ratio 2.0\n",
      "pause 990\n",
      "====================\n",
      "\n",
      "====================\n",
      "search_beginning_index 2\n",
      "haces 2 - 6\t aTes\n",
      "aquí 6 - 9\t aki\n",
      "--> default phrase duration 582\n",
      "--> at_default_phrase_duration 1732\n",
      "--> desired phrase duration 530.0\n",
      "====================\n",
      "interval (2, 9)\n",
      "ratio 0.9106529209621993\n",
      "pause 600\n",
      "====================\n",
      "\n",
      "====================\n",
      "search_beginning_index 9\n",
      "dónde 9 - 14\t donde\n",
      "estamos 14 - 21\t estamos\n",
      "--> default phrase duration 785\n",
      "--> at_default_phrase_duration 3117\n",
      "--> desired phrase duration 510.0000000000002\n",
      "====================\n",
      "interval (9, 21)\n",
      "ratio 0.6496815286624207\n",
      "pause 680\n",
      "====================\n",
      "\n",
      "--------------------========desired phrasing========--------------------\n",
      "[((0, 2), 2.0, 990), ((2, 9), 0.9106529209621993, 600), ((9, 21), 0.6496815286624207, 680)]\n",
      "desired_phrase_info: 0-2, 2.000000, 990.000000\n",
      "default_phoneme_info ('k', '112', [])\n",
      "new_phoneme_info ('k', '224', [])\n",
      "...\n",
      "default_phoneme_info ('e', '48', ['0', '114', '80', '107', '100', '107'])\n",
      "new_phoneme_info ('e', '96', ['0', '114', '80', '107', '100', '107'])\n",
      "...\n",
      "pause_info ('_', 990, [])\n",
      "desired_phrase_info: 2-9, 0.910653, 600.000000\n",
      "default_phoneme_info ('a', '47', ['0', '100', '80', '92', '100', '92'])\n",
      "new_phoneme_info ('a', '42', ['0', '100', '80', '92', '100', '92'])\n",
      "...\n",
      "default_phoneme_info ('T', '113', [])\n",
      "new_phoneme_info ('T', '102', [])\n",
      "...\n",
      "default_phoneme_info ('e', '41', ['0', '93', '80', '89', '100', '89'])\n",
      "new_phoneme_info ('e', '37', ['0', '93', '80', '89', '100', '89'])\n",
      "...\n",
      "default_phoneme_info ('s', '100', [])\n",
      "new_phoneme_info ('s', '91', [])\n",
      "...\n",
      "default_phoneme_info ('a', '33', ['0', '96', '80', '92', '100', '92'])\n",
      "new_phoneme_info ('a', '30', ['0', '96', '80', '92', '100', '92'])\n",
      "...\n",
      "default_phoneme_info ('k', '114', [])\n",
      "new_phoneme_info ('k', '103', [])\n",
      "...\n",
      "default_phoneme_info ('i', '134', ['0', '113', '13', '92', '26', '82', '53', '92', '80', '110', '100', '110'])\n",
      "new_phoneme_info ('i', '122', ['0', '113', '13', '92', '26', '82', '53', '92', '80', '110', '100', '110'])\n",
      "...\n",
      "pause_info ('_', 600, [])\n",
      "desired_phrase_info: 9-21, 0.649682, 680.000000\n",
      "default_phoneme_info ('d', '65', [])\n",
      "new_phoneme_info ('d', '42', [])\n",
      "...\n",
      "default_phoneme_info ('o', '45', ['0', '114', '80', '107', '100', '107'])\n",
      "new_phoneme_info ('o', '29', ['0', '114', '80', '107', '100', '107'])\n",
      "...\n",
      "default_phoneme_info ('n', '83', ['100', '100'])\n",
      "new_phoneme_info ('n', '53', ['100', '100'])\n",
      "...\n",
      "default_phoneme_info ('d', '65', [])\n",
      "new_phoneme_info ('d', '42', [])\n",
      "...\n",
      "default_phoneme_info ('e', '38', ['0', '108', '80', '104', '100', '104'])\n",
      "new_phoneme_info ('e', '24', ['0', '108', '80', '104', '100', '104'])\n",
      "...\n",
      "default_phoneme_info ('e', '32', ['0', '111', '80', '107', '100', '107'])\n",
      "new_phoneme_info ('e', '20', ['0', '111', '80', '107', '100', '107'])\n",
      "...\n",
      "default_phoneme_info ('s', '89', [])\n",
      "new_phoneme_info ('s', '57', [])\n",
      "...\n",
      "default_phoneme_info ('t', '50', [])\n",
      "new_phoneme_info ('t', '32', [])\n",
      "...\n",
      "default_phoneme_info ('a', '67', ['0', '112', '26', '91', '54', '82', '66', '83', '80', '86', '100', '86'])\n",
      "new_phoneme_info ('a', '43', ['0', '112', '26', '91', '54', '82', '66', '83', '80', '86', '100', '86'])\n",
      "...\n",
      "default_phoneme_info ('m', '65', [])\n",
      "new_phoneme_info ('m', '42', [])\n",
      "...\n",
      "default_phoneme_info ('o', '46', ['0', '88', '20', '92', '40', '96', '59', '100', '80', '104', '100', '104'])\n",
      "new_phoneme_info ('o', '29', ['0', '88', '20', '92', '40', '96', '59', '100', '80', '104', '100', '104'])\n",
      "...\n",
      "default_phoneme_info ('s', '140', [])\n",
      "new_phoneme_info ('s', '90', [])\n",
      "...\n",
      "pause_info ('_', 680, [])\n"
     ]
    }
   ],
   "source": [
    "#bend sample for synthesis\n",
    "sample_id = 's2_7_0247'\n",
    "phrase_structure_file = 'mt_output/' + sample_id + '.translation.structure.txt'\n",
    "default_pho_file = 'default_pho/' + sample_id + '.default.pho'\n",
    "#output_pho_file = sample_id + '.subunbent.pho'\n",
    "def_p = bend_pho_to_structure(phrase_structure_file, default_pho_file, output_pho_file=None, bend=True, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "asetSomutSopornosotrosemosetSomutSoportitantokenopodiamosaTerparati__sitebasaabandonar____\n",
      "['has', 'hecho', 'mucho', 'por', 'nosotros']\n",
      "mutSo\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "print(phoneme_seq)\n",
    "phrase_tokens, start_time, end_time, pause_after = phrase_structure[0]\n",
    "print(phrase_tokens)\n",
    "phoneme_rep = morpheme2phoneme(phrase_tokens[2], phonetic_dict)\n",
    "print(phoneme_rep)\n",
    "word_begin = phoneme_seq.find(phoneme_rep, 0)\n",
    "print(word_begin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s2_10_0080\n"
     ]
    }
   ],
   "source": [
    "#BEND ALL\n",
    "mt_output_dir = '/home/alp/Documents/playground-linux/SugarDub/mt_output'\n",
    "default_pho_dir = '/home/alp/Documents/playground-linux/SugarDub/default_pho/'\n",
    "bent_pho_dir = '/home/alp/Documents/playground-linux/SugarDub/sub_synthesis_redo/unbent_pho/'\n",
    "\n",
    "for root, direc, files in os.walk(mt_output_dir):\n",
    "    for file in files:\n",
    "        if file.endswith('structure.txt'):\n",
    "            \n",
    "            file_id = file.split('.')[0]\n",
    "            print(file_id)\n",
    "            \n",
    "            phrase_structure_file = os.path.join(mt_output_dir, file)\n",
    "            default_pho_file = os.path.join(default_pho_dir, file_id + '.default.pho')\n",
    "            bent_pho_out = os.path.join(bent_pho_dir, file_id + '.unbent.redo.pho')\n",
    "                                            \n",
    "            all_good, ratios = bend_pho_to_structure(phrase_structure_file, default_pho_file, bend=False, verbose=False)   \n",
    "            #all_good, _ = bend_pho_to_structure(phrase_structure_file, default_pho_file, bent_pho_out, bend=False, verbose=False)         \n",
    "            if not all_good:\n",
    "                print('problem', file_id)\n",
    "                \n",
    "            break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Functions for synthesis (doesn't work)\n",
    "def synthesize_pho(pho_file, output_wav):\n",
    "    command = 'mbrola ./es1/es1 ' + pho_file + ' ' + output_wav\n",
    "    cmd_tokens = command.split()\n",
    "    output = subprocess.check_output(cmd_tokens)\n",
    "    return output.decode()\n",
    "    print(command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#SYNTHESIZE ALL BENT FILES\n",
    "#~BASH: for i in `ls bent_pho`; do mbrola ./es1/es1 bent_pho/$i bent_synth/$i.wav; done"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
